{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Students performance and difficulties prediction\n",
    "\n",
    "In this notebook, we will  :\n",
    "\n",
    "- Predict whether or not a student will pass the final exam based on certain information given\n",
    "- Compare the three learning algorithms\n",
    "- Find out what most affects student achievement\n",
    "- Find the best algorithm with high accuracy\n",
    "\n",
    "We will be using three learning algorithms:\n",
    "\n",
    "- Logistic regression\n",
    "- Supported vector machine\n",
    "- KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, accuracy_score, f1_score, roc_auc_score\n",
    "from astropy.table import Table\n",
    "\n",
    "\n",
    "df = pd.read_csv('student-data.csv')\n",
    "dfv = pd.read_csv('student-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before process the data let's describe it briefly:**\n",
    "- Source : **Paulo Cortez, University of Minho, GuimarÃ£es, Portugal**, http://www3.dsi.uminho.pt/pcortez\n",
    "\n",
    "- This data approach student achievement in secondary education of two Portuguese schools.\n",
    "\n",
    "- The shape of our data set is **(395 rows × 31 columns)**.\n",
    "\n",
    "- **No missing** values in the data.\n",
    "\n",
    "- The data attributes **include demographic**, social and school related features and it was collected by using school reports and questionnaires.\n",
    "\n",
    "- **The last column tell us whether a student passed the final exam or not**.\n",
    "\n",
    "- The dataset is taken from : https://archive.ics.uci.edu/ml/datasets/student+performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now let's explain every column in the dataframe**\n",
    "- `school` : student's school (binary: \"GP\" or \"MS\")\n",
    "- `sex` : student's sex (binary: \"F\" - female or \"M\" - male)\n",
    "- `age` : student's age (numeric: from 15 to 22)\n",
    "- `address` : student's home address type (binary: \"U\" - urban or \"R\" - rural)\n",
    "- `famsize` : family size (binary: \"LE3\" - less or equal to 3 or \"GT3\" - greater than 3)\n",
    "- `Pstatus` : parent's cohabitation status (binary: \"T\" - living together or \"A\" - apart)\n",
    "- `Medu` : mother's education (numeric: 0 - none,  1 - primary education (4th grade), 2 - 5th to 9th grade, 3 - secondary education or 4 - higher education)\n",
    "- `Fedu` : father's education (numeric: 0 - none,  1 - primary education (4th grade), 2 - 5th to 9th grade, 3 - secondary education or 4 - higher education)\n",
    "- `Mjob` : mother's job (nominal: \"teacher\", \"health\" care related, civil \"services\" (e.g. administrative or police), \"at_home\" or \"other\")\n",
    "- `Fjob` : father's job (nominal: \"teacher\", \"health\" care related, civil \"services\" (e.g. administrative or police), \"at_home\" or \"other\")\n",
    "- `reason` : reason to choose this school (nominal: close to \"home\", school \"reputation\", \"course\" preference or \"other\")\n",
    "- `guardian` : student's guardian (nominal: \"mother\", \"father\" or \"other\")\n",
    "- `traveltime` : home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour)\n",
    "- `studytime` : weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)\n",
    "- `failures` : number of past class failures (numeric: n if 1<=n<3, else 4)\n",
    "- `schoolsup` : extra educational support (binary: yes or no)\n",
    "- `famsup` : family educational support (binary: yes or no)\n",
    "- `paid` : extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)\n",
    "- `activities` : extra-curricular activities (binary: yes or no)\n",
    "- `nursery` : attended nursery school (binary: yes or no)\n",
    "- `higher` : wants to take higher education (binary: yes or no)\n",
    "- `internet` : Internet access at home (binary: yes or no)\n",
    "- `romantic` : with a romantic relationship (binary: yes or no)\n",
    "- `famrel` : quality of family relationships (numeric: from 1 - very bad to 5 - excellent)\n",
    "- `freetime` : free time after school (numeric: from 1 - very low to 5 - very high)\n",
    "- `goout` : going out with friends (numeric: from 1 - very low to 5 - very high)\n",
    "- `Dalc` : workday alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "- `Walc` : weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "- `health` : current health status (numeric: from 1 - very bad to 5 - very good)\n",
    "- `absences` : number of school absences (numeric: from 0 to 93)\n",
    "\n",
    "**The last column:**\n",
    "- `passed` : did the student pass the final exam (binary: yes or no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Displaying the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping strings to numeric values:\n",
    "def numerical_data():\n",
    "    df['school'] = df['school'].map({'GP': 0, 'MS': 1})\n",
    "    df['sex'] = df['sex'].map({'M': 0, 'F': 1})\n",
    "    df['address'] = df['address'].map({'U': 0, 'R': 1})\n",
    "    df['famsize'] = df['famsize'].map({'LE3': 0, 'GT3': 1})\n",
    "    df['Pstatus'] = df['Pstatus'].map({'T': 0, 'A': 1})\n",
    "    df['Mjob'] = df['Mjob'].map({'teacher': 0, 'health': 1, 'services': 2, 'at_home': 3, 'other': 4})\n",
    "    df['Fjob'] = df['Fjob'].map({'teacher': 0, 'health': 1, 'services': 2, 'at_home': 3, 'other': 4})\n",
    "    df['reason'] = df['reason'].map({'home': 0, 'reputation': 1, 'course': 2, 'other': 3})\n",
    "    df['guardian'] = df['guardian'].map({'mother': 0, 'father': 1, 'other': 2})\n",
    "    df['schoolsup'] = df['schoolsup'].map({'no': 0, 'yes': 1})\n",
    "    df['famsup'] = df['famsup'].map({'no': 0, 'yes': 1})\n",
    "    df['paid'] = df['paid'].map({'no': 0, 'yes': 1})\n",
    "    df['activities'] = df['activities'].map({'no': 0, 'yes': 1})\n",
    "    df['nursery'] = df['nursery'].map({'no': 0, 'yes': 1})\n",
    "    df['higher'] = df['higher'].map({'no': 0, 'yes': 1})\n",
    "    df['internet'] = df['internet'].map({'no': 0, 'yes': 1})\n",
    "    df['romantic'] = df['romantic'].map({'no': 0, 'yes' : 1})\n",
    "    df['passed'] = df['passed'].map({'no': 0, 'yes': 1})\n",
    "    # reorder dataframe columns :\n",
    "    col = df['passed']\n",
    "    del df['passed']\n",
    "    df['passed'] = col\n",
    "\n",
    "    \n",
    "# feature scaling will allow the algorithm to converge faster, large data will have same scal\n",
    "def feature_scaling(df):\n",
    "    for i in df:\n",
    "        col = df[i]\n",
    "        # let's choose columns that have large values\n",
    "        if(np.max(col)>6):\n",
    "            Max = max(col)\n",
    "            Min = min(col)\n",
    "            mean = np.mean(col)\n",
    "            col  = (col-mean)/(Max)\n",
    "            df[i] = col\n",
    "        elif(np.max(col)<6):\n",
    "            col = (col-np.min(col))\n",
    "            col /= np.max(col)\n",
    "            df[i] = col\n",
    "        \n",
    "# This function will transform dataframe to a numpy array and split it\n",
    "def split(df,test_size):\n",
    "    data = df.to_numpy()\n",
    "    n = data.shape[1]\n",
    "    x = data[:,0:n-1]\n",
    "    y = data[:,n-1]\n",
    "    X_train,X_test,y_train,y_test = train_test_split(x,y,test_size=test_size, random_state=0)\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**digitization of values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All values in numerical after calling numerical_data() function\n",
    "numerical_data()\n",
    "df.iloc[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna().shape # their is no null value \"fortunately:)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Now let's visualise the data and look deeper into each features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu',\n",
    "       'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime',\n",
    "       'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery',\n",
    "       'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc',\n",
    "       'Walc', 'health', 'absences']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) boxplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"passed\", y=\"goout\",  data=dfv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it seems that even people with low number of gout hours failed the exam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " b) Distribution of categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     -for school Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfv[\"school\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,fx = plt.subplots() \n",
    "figure = sns.countplot(x = 'school', data=dfv, order=['GP','MS'])\n",
    "fx = fx.set(ylabel=\"Count\", xlabel=\"school\")\n",
    "figure.grid(False)\n",
    "plt.title('School Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "      -for gender Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, fx = plt.subplots()\n",
    "f = sns.countplot(x = 'sex', data=dfv, order=['M','F'])\n",
    "fx = fx.set(ylabel=\"Count\", xlabel=\"gender\")\n",
    "f.grid(False)\n",
    "plt.title('Gender Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     -for Address Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, fx = plt.subplots()\n",
    "figure = sns.countplot(x = 'address', data=dfv, order=['U','R'])\n",
    "fx = fx.set(ylabel=\"Count\", xlabel=\"address\")\n",
    "figure.grid(False)\n",
    "plt.title('Address Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    -for family Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfv[\"famsize\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, fx = plt.subplots()\n",
    "figure = sns.countplot(x = 'famsize', data=dfv, order=['GT3','LE3'])\n",
    "fx = fx.set(ylabel=\"Count\", xlabel=\"famsize\")\n",
    "figure.grid(False)\n",
    "plt.title('Family Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "          -Parents status Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, fx = plt.subplots()\n",
    "figure = sns.countplot(x = 'Pstatus', data=dfv, order=['A','T'])\n",
    "fx = fx.set(ylabel=\"Count\", xlabel=\"status\")\n",
    "figure.grid(False)\n",
    "plt.title('Parents status Distribution')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     -School Support Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, fx = plt.subplots()\n",
    "figure = sns.countplot(x = 'schoolsup', data=dfv, order=['yes','no'])\n",
    "fx = fx.set(ylabel=\"Count\", xlabel=\"School Support\")\n",
    "figure.grid(False)\n",
    "plt.title('School Support Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    -Family Support Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, fx = plt.subplots()\n",
    "figure = sns.countplot(x = 'famsup', data=dfv, order=['yes','no'])\n",
    "fx = fx.set(ylabel=\"Count\", xlabel=\"Family Support\")\n",
    "figure.grid(False)\n",
    "plt.title('Family Support Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    -for extra paid distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, fx = plt.subplots()\n",
    "figure = sns.countplot(x = 'paid', data=dfv, order=['yes','no'])\n",
    "fx = fx.set(ylabel=\"Count\", xlabel=\"extra paid classes\")\n",
    "figure.grid(False)\n",
    "plt.title('Extra paid classes Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Students who want to take higher education Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, fx = plt.subplots()\n",
    "figure = sns.countplot(x = 'higher', data=dfv, order=['yes','no'])\n",
    "fx = fx.set(ylabel=\"Count\", xlabel=\"wants to take higher education\")\n",
    "figure.grid(False)\n",
    "plt.title('Students who want to take higher education Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    -  internet Accessibility at home Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, fx = plt.subplots()\n",
    "figure = sns.countplot(x = 'internet', data=dfv, order=['yes','no'])\n",
    "fx = fx.set(ylabel=\"Count\", xlabel=\"Internet access at home\")\n",
    "figure.grid(False)\n",
    "plt.title('Internet access at home Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "       -Students with a romantic relationship Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, fx = plt.subplots()\n",
    "figure = sns.countplot(x = 'romantic', data=dfv, order=['yes','no'])\n",
    "fx = fx.set(ylabel=\"Count\", xlabel=\"With a romantic relationship\")\n",
    "figure.grid(False)\n",
    "plt.title('Students with a romantic relationship Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " c) Distribution of  features with multiple categoric "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "               - Parent_Education_Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(numeric: 0 - none, 1 - primary education (4th grade), 2 - 5th to 9th grade, 3 - secondary education or 4 - higher education)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfv[\"Medu\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfv[\"Fedu\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, fx = plt.subplots()\n",
    "figure = sns.countplot(x = 'Medu', data=dfv, order=[0,1,2,3,4])\n",
    "fx = fx.set(ylabel=\"Count\", xlabel=\"Mother Education\")\n",
    "figure.grid(False)\n",
    "plt.title('Parent Education Distribution')\n",
    "   \n",
    "f, fx = plt.subplots()\n",
    "figure = sns.countplot(x = 'Fedu', data=dfv, order=[0,1,2,3,4])\n",
    "fx = fx.set(ylabel=\"Count\", xlabel=\"Father Education\")\n",
    "figure.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, fx = plt.subplots()\n",
    "figure = sns.countplot(x = 'Mjob', data=dfv, order=['teacher','health','services','at_home','other'])\n",
    "fx = fx.set(ylabel=\"Count\", xlabel=\"Mother Job\")\n",
    "figure.grid(False)\n",
    "plt.title('Parent Job Distribution')\n",
    "   \n",
    "f, fx = plt.subplots()\n",
    "figure = sns.countplot(x = 'Fjob', data=dfv, order=['teacher','health','services','at_home','other'])\n",
    "fx = fx.set(ylabel=\"Count\", xlabel=\"Father Job\")\n",
    "figure.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    -travel_time_Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "figure = sns.countplot(x = 'traveltime', data=dfv, order=[1,2,3,4])\n",
    "ax = ax.set(ylabel=\"Count\", xlabel=\"travel time\")\n",
    "figure.grid(False)\n",
    "plt.title('Travel Time Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "      -Study Time Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "figure = sns.countplot(x = 'studytime', data=dfv, order=[1,2,3,4])\n",
    "ax = ax.set(ylabel=\"Count\", xlabel=\"study time\")\n",
    "figure.grid(False)\n",
    "plt.title('Study Time Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "           -failures Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "figure = sns.countplot(x = 'failures', data=dfv, order=[0,1,2,3])\n",
    "ax = ax.set(ylabel=\"Count\", xlabel=\"failures\")\n",
    "figure.grid(False)\n",
    "plt.title('failures Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     -family relationship Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "figure = sns.countplot(x = 'famrel', data=dfv, order=[1,2,3,4,5])\n",
    "ax = ax.set(ylabel=\"Count\", xlabel=\"family relationship\")\n",
    "figure.grid(False)\n",
    "plt.title('family relationship Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     -Free time Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "figure = sns.countplot(x = 'freetime', data=dfv, order=[1,2,3,4,5])\n",
    "ax = ax.set(ylabel=\"Count\", xlabel=\"Freetime\")\n",
    "figure.grid(False)\n",
    "plt.title('Free time Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     -Going Out Distribution\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "figure = sns.countplot(x = 'goout', data=dfv, order=[1,2,3,4,5])\n",
    "ax = ax.set(ylabel=\"Count\", xlabel=\"Going Out\")\n",
    "figure.grid(False)\n",
    "plt.title('Going Out Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    -alcohol consumption Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "figure = sns.countplot(x = 'Dalc', data=dfv, order=[1,2,3,4,5])\n",
    "ax = ax.set(ylabel=\"Count\", xlabel=\"Working\")\n",
    "figure.grid(False)\n",
    "plt.title('Working day alcohol consumption Distribution')\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "figure = sns.countplot(x = 'Walc', data=dfv, order=[1,2,3,4,5])\n",
    "ax = ax.set(ylabel=\"Count\", xlabel=\"Weekends\")\n",
    "figure.grid(False)\n",
    "plt.title('Weekend alcohol consumption Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    -distribution of student status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfv['passed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 'student pass the final exam ', 'student fail the final exam'\n",
    "sizes = [265, 130]\n",
    "colors=['lightskyblue','yellow']\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes,  labels=labels, autopct='%1.1f%%',colors=colors,\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   d) Now leats look at the most impactufull features for student failure\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                 1-using correlation \n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise correlation between student status and other features\n",
    "plt.figure(figsize=(8, 12))\n",
    "heatmap = sns.heatmap(df.corr()[['passed']].sort_values(by='passed', ascending=False), vmin=-1, vmax=1, annot=True, cmap='BrBG')\n",
    "heatmap.set_title('Features Correlating with the status of student', fontdict={'fontsize':18}, pad=16);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it seems that most impactefull elements for student status are :\n",
    "\n",
    "    _ for negatif impact we had:\n",
    "    \n",
    "        -failures\n",
    "        -goout\n",
    "        -age\n",
    "        \n",
    "    _ for positif impact\n",
    "    \n",
    "       -heigher\n",
    "        -Medu\n",
    "        -Fedu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Features scalling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_scaling(df)\n",
    "X_train,X_test,y_train,y_test = split(df,0.2)\n",
    "\n",
    "# Now we are ready for models training\n",
    "df.iloc[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réalisée par el nabaoui nouhaila"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will discuss how to implement knn and how to get best accuracy using hyperparametters tuning (good lecture:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call  feature_scaling function:\n",
    "#define data\n",
    "y=df.passed\n",
    "target=[\"passed\"]\n",
    "X = df.drop(target,axis = 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A)**Hyperparameter Tuning**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before appling the knn algorithme it could be better to choose an optimal value of k,but what is the best method to tun this value ?\n",
    "Actually There is no straightforward method to calculate the value of K in KNN. We have to play around with different values to choose the optimal value of K. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting the data\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0, stratify=y)\n",
    "#Setup arrays to store training and test accuracies\n",
    "neighbors= np.arange(1,20)\n",
    "train_accuracy =np.empty(19)\n",
    "test_accuracy = np.empty(19)\n",
    "\n",
    "for i,k in enumerate(neighbors):\n",
    "    #Setup a knn classifier with k neighbors\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    #Fit the model\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    #Compute accuracy on the training set\n",
    "    train_accuracy[i] = knn.score(X_train, y_train)\n",
    "    \n",
    "    #Compute accuracy on the test set\n",
    "    test_accuracy[i] = knn.score(X_test, y_test) \n",
    "    \n",
    "#  Plotting the curv\n",
    "plt.title('k-NN Varying number of neighbors')\n",
    "plt.plot(neighbors, test_accuracy, label='Testing Accuracy')\n",
    "plt.plot(neighbors, train_accuracy, label='Training accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case study we had a binary classification sow it could be better to choose an odd value of K.\n",
    "By looking into the curv we might see that k=13 could be good choise .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**we are going to search for Best parameters(K,metric)  based on time,acc using validation data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"n_neighbors\": np.arange(1, 30), \"metric\":[\"euclidean\", \"manhattan\", \"chebyshev\"]}\n",
    "acc = {}\n",
    "i=0\n",
    "\n",
    "for m in params[\"metric\"]:\n",
    "    acc[m] = []\n",
    "    for k in params[\"n_neighbors\"]:\n",
    "        print(\"Model_{} metric: {}, n_neighbors: {}\".format(i, m, k))\n",
    "        i += 1\n",
    "        t = time()\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, metric=m)\n",
    "        knn.fit(X_train,y_train)\n",
    "        pred = knn.predict(X_test)\n",
    "        print(\"Time: \", time() - t)\n",
    "        acc[m].append(accuracy_score(y_test, pred))\n",
    "        print(\"Acc: \", acc[m][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as  We can see that the best metric or distance is manhattan_distance,optimal k=8. This choice  gives heigh Acc=68% with less time consuming compared to other distances(t=0.007990360260009766 s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B)Final models implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we discover in privious section the best parameters to implement knn algorithme are:\n",
    "\n",
    "    -K=13\n",
    "    \n",
    "    -metric=euclidian-distance\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finale model\n",
    "knn_f=KNeighborsClassifier(n_neighbors=13,metric='euclidean')\n",
    "knn_f.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C)Model evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To evaluate our  model we are going to**:\n",
    "\n",
    "-use heatmap (matrice de confusion )\n",
    "\n",
    "-use the precision recall and  F1 score for each class\n",
    "\n",
    "-plotting the roc curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)**Confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at first let choose k=11 and evaluate the acquracy:\n",
    "y_predict=knn_f.predict(X_test)\n",
    "ac1 = accuracy_score(y_test,y_predict)\n",
    "print('Accuracy is: ',ac1)\n",
    "cm= confusion_matrix(y_test,y_predict)\n",
    "sns.heatmap(cm,annot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)**classification_report**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "y_predict = knn_f.predict(X_test)\n",
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3)**Roc_curv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting the roc_curve\n",
    "\n",
    "fpositif, tpositif, thresholds = roc_curve(y_test, y_predict)\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.plot(fpositif,tpositif, label='knn_f')\n",
    "plt.xlabel('false positif')\n",
    "plt.ylabel('true positif')\n",
    "plt.title('Knn_f ROC curve')\n",
    "p=plt.show()\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D)conclusion :\n",
    "To conclude after using knn algorithme with(euclidian_distance,k=13) we got a quit good accuracy acc=70%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support vector machine "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First of all let's start with creating some useful functions :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mohammed AL JADD\n",
    "# Functions will help us\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "# Show results of every model-\n",
    "\n",
    "def showResults(accuracy, trainingTime, y_pred,model):\n",
    "    \n",
    "    print('------------------------------------------------Results :',model,'-----------------------------------------------------')\n",
    "    confusionMatrix = confusion_matrix(y_test, y_pred)\n",
    "    print('\\n The ROC curve is :\\n')\n",
    "    fpr,tpr,thresholds=roc_curve(y_test,y_pred)\n",
    "    plt.plot([0, 1],[0, 1],'--')\n",
    "    plt.plot(fpr,tpr,label=model)\n",
    "    plt.xlabel('false positive')\n",
    "    plt.ylabel('false negative')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print('----------------------------------------------')\n",
    "    print('The model  accuracy:', accuracy,'%')\n",
    "    print('----------------------------------------------')\n",
    "    print('The confusion matrix is :\\n',confusionMatrix)\n",
    "    print('----------------------------------------------')\n",
    "    print('The training time is: ',trainingTime)\n",
    "    print('----------------------------------------------')\n",
    "    print('The f1 score is :',f1_score(y_test, y_pred, average='macro'))\n",
    "    print('----------------------------------------------')\n",
    "    print('The roc_auc_score is :',roc_auc_score(y_test, y_pred))  \n",
    "    print('--------------------------------------------------------------------------------------------------------------------')\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "# Hyperparameter Tuning :\n",
    "# C, degree and gamma are the parameters that are used in SVM classffier 'svc(C=..,..),svc(C,degree=..)',svc(C,gamma=..)\n",
    "# The following functions will return those values that minimize the error on (X_val,y_val) set\n",
    "# So this (X_val,y_val) set will be used to get the optimal SVM parameters before evaluating the model on the test set\n",
    "\n",
    "\n",
    "# Optimal C \n",
    "def optimal_C_value():\n",
    "    Ci = np.array(( 0.0001,0.001,0.01,0.05,0.1,4,10,40,100))\n",
    "    minError = float('Inf')\n",
    "    optimal_C = float('Inf')\n",
    "\n",
    "    for c in Ci:\n",
    "        clf = SVC(C=c,kernel='linear')\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_val)\n",
    "        error = np.mean(np.double(predictions != y_val))\n",
    "        if error < minError:\n",
    "            minError = error\n",
    "            optimal_C = c\n",
    "    return optimal_C\n",
    "\n",
    "\n",
    "# Optimal C and the degree of the polynomial\n",
    "def optimal_C_d_values():\n",
    "    Ci = np.array(( 0.0001,0.001,0.01,0.05,0.1,4,10,40,100))\n",
    "    Di = np.array(( 2, 5, 10, 15, 20, 25, 30))\n",
    "    minError = float('Inf')\n",
    "    optimal_C = float('Inf')\n",
    "    optimal_d = float('Inf')\n",
    "\n",
    "    for d in Di:\n",
    "        for c in Ci:\n",
    "            clf = SVC(C=c,kernel='poly', degree=d)\n",
    "            clf.fit(X_train, y_train)\n",
    "            predictions = clf.predict(X_val)\n",
    "            error = np.mean(np.double(predictions != y_val))\n",
    "            if error < minError:\n",
    "                minError = error\n",
    "                optimal_C = c\n",
    "                optimal_d = d\n",
    "    return optimal_C,optimal_d\n",
    "\n",
    "\n",
    "# Optimal C and gamma\n",
    "def optimal_C_gamma_values():\n",
    "    Ci = np.array(( 0.0001,0.001,0.01,0.05,0.1,4,10,40,100))\n",
    "    Gi = np.array(( 0.000001,0.00001,0.01,1,2,3,5,20,70,100,500,1000))\n",
    "    minError = float('Inf')\n",
    "    optimal_C = float('Inf')\n",
    "    optimal_g = float('Inf')\n",
    "\n",
    "    for g in Gi:\n",
    "        for c in Ci:\n",
    "            clf = SVC(C=c,kernel='rbf', gamma=g)\n",
    "            clf.fit(X_train, y_train)\n",
    "            predictions = clf.predict(X_val)\n",
    "            error = np.mean(np.double(predictions != y_val))\n",
    "            if error < minError:\n",
    "                minError = error\n",
    "                optimal_C = c\n",
    "                optimal_g = g\n",
    "    return optimal_C,optimal_g\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "# Compare the three kernels\n",
    "\n",
    "\n",
    "def compare_kernels():\n",
    "    print('------------------------------------------------ Comparison -----------------------------------------------------')\n",
    "    print('\\n')\n",
    "    f11 = \"{:.2f}\".format(f1_score(y_test, y_linear, average='macro'))\n",
    "    f22 = \"{:.2f}\".format(f1_score(y_test, y_poly, average='macro'))\n",
    "    f33 = \"{:.2f}\".format(f1_score(y_test, y_gauss, average='macro'))\n",
    "    roc1 = \"{:.2f}\".format(roc_auc_score(y_test, y_linear))\n",
    "    roc2 = \"{:.2f}\".format(roc_auc_score(y_test, y_poly))\n",
    "    roc3 = \"{:.2f}\".format(roc_auc_score(y_test, y_gauss))\n",
    "    a1,a2 = confusion_matrix(y_test, y_linear)[0],confusion_matrix(y_test, y_linear)[1]\n",
    "    b1,b2 = confusion_matrix(y_test, y_poly)[0],confusion_matrix(y_test, y_poly)[1]\n",
    "    c1,c2 = confusion_matrix(y_test, y_gauss)[0],confusion_matrix(y_test, y_gauss)[1]\n",
    "    data_rows = [('training time',time1, time2, time3),\n",
    "                 ('','','',''),\n",
    "                  ('accuracy %',linear_accuracy, poly_accuracy, gauss_accuracy),\n",
    "                 ('','','',''),\n",
    "                 ('confusion matrix',a1, b1, c1),\n",
    "                ('',a2,b2,c2),\n",
    "                 ('','','',''),\n",
    "                ('f1 score',f11,f22,f33),\n",
    "                 ('','','',''),\n",
    "                ('roc_auc_score',roc1,roc2,roc3)]\n",
    "    t = Table(rows=data_rows, names=('metrice','Linear kernel', 'polynomial kernel', 'gaussian kernel'))\n",
    "    print(t)\n",
    "    print('\\n\\n')\n",
    "    print('The Roc curves :\\n')\n",
    "    y_pred1 = y_linear\n",
    "    y_pred2 = y_poly\n",
    "    y_pred3 = y_gauss\n",
    "    \n",
    "    fpr,tpr,thresholds=roc_curve(y_test,y_pred1)\n",
    "    plt.plot([0, 1],[0, 1],'--')\n",
    "    plt.plot(fpr,tpr,label='Linear kernel')\n",
    "    plt.xlabel('false positive')\n",
    "    plt.ylabel('false negative')\n",
    "    fpr,tpr,thresholds=roc_curve(y_test,y_pred2)\n",
    "    plt.plot(fpr,tpr,label='Polynomial kernel')\n",
    "    fpr,tpr,thresholds=roc_curve(y_test,y_pred3)\n",
    "    plt.plot(fpr,tpr,label='Gaussian kernel')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "# Print results of the choosen kernel\n",
    "\n",
    "def best_kernel(kernel):\n",
    "    time = 0\n",
    "    f1 = 0\n",
    "    accuracy = 0\n",
    "    rc = 0\n",
    "    y = 0\n",
    "    if kernel == 'linear kernel':\n",
    "        time = time1\n",
    "        f1 = \"{:.2f}\".format(f1_score(y_test, y_linear, average='macro'))\n",
    "        accuracy = linear_accuracy\n",
    "        rc = roc_auc_score(y_test, y_linear)\n",
    "        y = y_linear\n",
    "    elif kernel == 'polynomial kernel':\n",
    "        time = time2\n",
    "        f1 = \"{:.2f}\".format(f1_score(y_test, y_poly, average='macro'))\n",
    "        accuracy = poly_accuracy\n",
    "        rc = roc_auc_score(y_test, y_poly)\n",
    "        y = y_poly\n",
    "    else :\n",
    "        time = time3\n",
    "        f1 = \"{:.2f}\".format(f1_score(y_test, y_gauss, average='macro'))\n",
    "        accuracy = gauss_accuracy\n",
    "        rc = roc_auc_score(y_test, y_gauss)\n",
    "        y = y_gauss\n",
    "    print('The choosen kernel :',kernel)\n",
    "    print('the training :',time)\n",
    "    print('the accuracy :',round(accuracy),'%')\n",
    "    print('the f1 score :',f1)\n",
    "    print('The roc_auc_score is :',rc)\n",
    "    print('----------------------------------------\\nThe ROC curve :')\n",
    "    fpr,tpr,thresholds=roc_curve(y_test,y)\n",
    "    plt.plot([0, 1],[0, 1],'--')\n",
    "    plt.plot(fpr,tpr,label='The best svm kernel : '+kernel)\n",
    "    plt.xlabel('false positive')\n",
    "    plt.ylabel('false negative')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "# Splitting the data for SVM\n",
    "# Here We will split data into test set, cross validation (X_val, y_val) set and training set\n",
    "# The cross validation (X_val, y_val) is used for choosing the optimal value for svm parameters C, degree and gamma\n",
    "data = df.to_numpy()\n",
    "n = data.shape[1]    \n",
    "x = data[:,0:n-1]\n",
    "y = data[:,n-1]\n",
    "X_train,X_rest,y_train,y_rest = train_test_split(x,y,test_size=0.4, random_state=0)\n",
    "X_val,X_test,y_val,y_test = train_test_split(X_rest,y_rest,test_size=0.4, random_state=0) \n",
    "\n",
    "# We will use the three different svm classifier kernels\n",
    "# Linear kernel, polynomial kernel and gaussian kernel and we will choose the most accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1) Model evaluation:</h3>\n",
    "\n",
    "For model evaluation we will calculate :\n",
    "\n",
    "- <span style='color:red'>**Training time**</span>\n",
    "- <span style='color:red'>**Accuracy**</span>\n",
    "- <span style='color:red'>**Confusion matrix**</span>\n",
    "- <span style='color:red'>**ROC curve**</span>\n",
    "- <span style='color:red'>**ROC score**</span>\n",
    "- <span style='color:red'>**f1 score**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2) Training phase:</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Kernel :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################### Linear kernel ###########################################################\n",
    "\n",
    "# Let's get the optimal C value for the linear kernal\n",
    "optimal_C = optimal_C_value()\n",
    "\n",
    "\n",
    "# Now let's use the optimal C value\n",
    "linear_clf = SVC(C=optimal_C,kernel='linear')\n",
    "\n",
    "# Let's train the model with the optimal C value and calculate the training time\n",
    "tic = time()\n",
    "linear_clf.fit(X_train, y_train)\n",
    "toc = time()\n",
    "time1 = str(round(1000*(toc-tic))) + \"ms\"\n",
    "y_linear = linear_clf.predict(X_test)\n",
    "linear_accuracy = accuracy_score(y_test, y_linear)*100\n",
    "\n",
    "\n",
    "\n",
    "# Let's show the resuls\n",
    "showResults(linear_accuracy, time1, y_linear,'SVM linear kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Polynomial Kernel :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################### Polynomial kernel ######################################################\n",
    "\n",
    "# Let's get the optimal C and the degree value for the polynomial kernal\n",
    "optimal_C, optimal_d = optimal_C_d_values()\n",
    "\n",
    "# Now let's use the optimal c value and the optimal degree value\n",
    "poly_clf = SVC(C=optimal_C,kernel='poly', degree=optimal_d)\n",
    "\n",
    "# Let's train the model with the optimal C value and calculate the training time\n",
    "tic = time()\n",
    "poly_clf.fit(X_train, y_train)\n",
    "toc = time()\n",
    "time2 = str(round(1000*(toc-tic))) + \"ms\"\n",
    "y_poly = poly_clf.predict(X_test)\n",
    "poly_accuracy = (accuracy_score(y_test, y_poly)*100)\n",
    "\n",
    "# Let's show the resuls\n",
    "showResults(poly_accuracy, time2, y_poly,'SVM polynomial kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gaussian Kernel :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################### Gaussian kernel ######################################################\n",
    "\n",
    "# Let's get the optimal C value for the gaussian kernal\n",
    "optimal_C, optimal_gamma = optimal_C_gamma_values() \n",
    "\n",
    "# Now let's use the optimal c value\n",
    "gauss_clf = SVC(C=optimal_C,kernel='rbf',gamma=optimal_gamma)\n",
    "\n",
    "# Let's train the model with the optimal C value and calculate the training time\n",
    "tic = time()\n",
    "gauss_clf.fit(X_train, y_train)\n",
    "toc = time()\n",
    "time3 = str(round(1000*(toc-tic))) + \"ms\"\n",
    "y_gauss = gauss_clf.predict(X_test)\n",
    "gauss_accuracy = (accuracy_score(y_test, y_gauss)*100)\n",
    "\n",
    "# Let's show the resuls\n",
    "showResults(gauss_accuracy, time3, y_gauss,'SVM gaussian kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3) Comparison of the three svm kernels:</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will compare all the metrics and plots one graph containing all the three ROC curves of the three SVM kernels :**\n",
    "\n",
    "```python\n",
    "# we will just call the function :\n",
    "compare_kernels()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_kernels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>4) The most accurate svm kernel is the linear kernel:</h3>\n",
    "\n",
    "```python\n",
    "# ust call the function :\n",
    "best_kernel(\"linear kernel\"), \n",
    "#we give it the parameter \"linear kernel\" as it's it's the most accurate.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_kernel('linear kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>5) Factors affecting performances of studens :</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>6) Conclusion : SVM linear kernel:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of the three algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
